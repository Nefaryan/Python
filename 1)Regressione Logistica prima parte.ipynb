{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressione Logistica in Python\n",
    "### Pacchetti Python di regressione logistica\n",
    "Esistono diversi pacchetti necessari per la regressione logistica in Python. Sono tutti gratuiti e open source, con molte risorse disponibili. Innanzitutto avremo bisogno di NumPy , sappiamo gi√† che √® un pacchetto fondamentale per il calcolo scientifico e numerico in Python. \n",
    "\n",
    "L'altro pacchetto Python che utilizzeremo √® scikit-learn, come gi√† sappiamo √® una delle librerie di data science e machine learning pi√π popolari in python che possiamo utilizzare per:\n",
    "- Preelaborare i dati\n",
    "- Ridurre la dimensionalit√† dei problemi\n",
    "- Convalidare i modelli\n",
    "- Seleziona il modello pi√π appropriato\n",
    "- Risolvere problemi di regressione e classificazione\n",
    "- Implementare l'analisi dei cluster\n",
    "\n",
    "Infine, utilizzeremo Matplotlib per visualizzare i risultati della nostra classificazione. \n",
    "\n",
    "## Regressione logistica in Python con scikit-learn: Esempio 1\n",
    "Il primo esempio √® legato ad un problema di classificazione binaria a variabile singola. Questo √® il tipo pi√π semplice di problema di classificazione. I diversi passaggi generali da eseguire durante la preparazione dei modelli di classificazione sono:\n",
    "\n",
    "- Importare pacchetti, funzioni e classi\n",
    "- Ottienere dati con cui lavorare e, se appropriato, trasformali\n",
    "- Creare un modello di classificazione e addestralo (o adattalo) ai dati esistenti\n",
    "- Valutare il tuo modello per vedere se le sue prestazioni sono soddisfacenti\n",
    "\n",
    "quindi andiamo al sodo...\n",
    "\n",
    "### Passaggio 1: importare pacchetti, funzioni e classi\n",
    "Innanzitutto, dobbiamo importare Matplotlib per la visualizzazione e NumPy per le operazioni sugli array. Avremo anche bisogno LogisticRegression di , classification_report(), e confusion_matrix() da scikit-learn:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora abbiamo importato tutto il necessario per la regressione logistica in Python con scikit-learn!\n",
    "\n",
    "### Passaggio 2: ottieniamo i dati\n",
    "In pratica, di solito avremo alcuni dati con cui lavorare. Ai fini di questo esempio, creiamo semplicemente array per i valori di input (ùë•) e di output (ùë¶):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'input e l'output dovrebbero essere array NumPy (istanze della classe numpy.ndarray) o oggetti simili. numpy.arange() come sappiamo crea una matrice di valori consecutivi equidistanti all'interno di un determinato intervallo. \n",
    "\n",
    "L'array X deve essere bidimensionale . Dovrebbe avere una colonna per ogni input e il numero di righe dovrebbe essere uguale al numero di osservazioni. Per renderlo bidimensionale, applichiamo come in precedenza .reshape() e -1 per ottenere tutte le righe necessarie e 1 per ottenere una colonna. \n",
    "\n",
    "Quindi X ha due dimensioni:\n",
    "\n",
    "- Una colonna per un singolo input;\n",
    "- Dieci righe , ciascuna corrispondente a un'osservazione.\n",
    "\n",
    "y √® unidimensionale con dieci elementi. \n",
    "Anche in questo caso ogni item corrisponde a un'osservazione. Contiene solo zeri e uno poich√© si tratta di un problema di classificazione binaria.\n",
    "\n",
    "### Passaggio 3: creiamo un modello e addestriamolo\n",
    "Una volta preparati l'input e l'output, √® possibile creare e definire il modello di classificazione. \n",
    "Lo rappresenteremo con un'istanza della classe LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'istruzione precedente crea un'istanza LogisticRegressione associa i suoi riferimenti alla variabile model. LogisticRegression ha diversi parametri opzionali che definiscono il comportamento del modello e dell'approccio:\n",
    "\n",
    "- penalty √® una stringa ( 'l2'per impostazione predefinita) che decide se esiste la regolarizzazione e quale approccio utilizzare. Altre opzioni sono 'l1', 'elasticnet'e 'none'.\n",
    "\n",
    "- dual √® un valore booleano ( False per impostazione predefinita) che decide se utilizzare la False formulazione primale (quando) o doppia (quando True).\n",
    "\n",
    "- tol √® un numero in virgola mobile ( 0.0001 per impostazione predefinita) che definisce la tolleranza per l'interruzione della procedura.\n",
    "\n",
    "- C √® un numero a virgola mobile positivo ( 1.0 per impostazione predefinita) che definisce la forza relativa della regolarizzazione. Valori pi√π piccoli indicano una regolarizzazione pi√π forte.\n",
    "\n",
    "- fit_intercept √® un booleano ( True di default) che decide se calcolare l'intercetta ùëè‚ÇÄ (quando True) o considerarla uguale a zero (quando False).\n",
    "\n",
    "- intercept_scaling √® un numero in virgola mobile ( 1.0 per impostazione predefinita) che definisce il ridimensionamento dell'intercetta ùëè‚ÇÄ.\n",
    "\n",
    "- class_weight √® un dizionario, 'balanced', o None (predefinito) che definisce i pesi relativi a ciascuna classe. Quando None, tutte le classi hanno lo stesso peso.\n",
    "\n",
    "- random_state √® un numero intero, un'istanza di numpy.RandomState, None (predefinito) che definisce quale generatore di numeri pseudo-casuali utilizzare.\n",
    "\n",
    "- solver √® una stringa ( 'liblinear' per impostazione predefinita) che decide quale risolutore utilizzare per adattare il modello. Altre opzioni sono 'newton-cg', 'lbfgs', 'sag'e 'saga'.\n",
    "\n",
    "- max_iter √® un numero intero ( 100 per impostazione predefinita) che definisce il numero massimo di iterazioni da parte del risolutore durante l'adattamento del modello.\n",
    "\n",
    "- multi_class √® una stringa ( 'ovr' per impostazione predefinita) che decide l'approccio da utilizzare per la gestione di pi√π classi. Altre opzioni sono 'multinomial'e 'auto'.\n",
    "\n",
    "- verbose √® un numero intero non negativo ( 0 per impostazione predefinita) che definisce la verbosit√† per i solutori 'liblinear'e 'lbfgs'.\n",
    "\n",
    "- warm_start √® un booleano ( False di default) che decide se riutilizzare la soluzione ottenuta in precedenza.\n",
    "\n",
    "- n_jobs √® un numero intero o None (predefinito) che definisce il numero di processi paralleli da utilizzare. None di solito significa utilizzare un core, mentre -1 significa utilizzare tutti i core disponibili.\n",
    "\n",
    "- l1_ratio √® un numero a virgola mobile compreso tra zero e uno oppure None(impostazione predefinita). Definisce l'importanza relativa della parte L1 nella regolarizzazione della rete elastica.\n",
    "\n",
    "√à necessario abbinare attentamente il risolutore e il metodo di regolarizzazione per diversi motivi:\n",
    "\n",
    "- 'liblinear' il risolutore non funziona senza regolarizzazione.\n",
    "- 'newton-cg', 'sag', 'saga' e 'lbfgs' non supportano la regolarizzazione L1.\n",
    "- 'saga' √® l'unico solutore che supporta la regolarizzazione della rete elastica.\n",
    "\n",
    "Una volta creato il modello, √® necessario adattarlo (o addestrarlo). L'adattamento del modello √® il processo di determinazione dei coefficienti ùëè‚ÇÄ, ùëè‚ÇÅ, ‚Ä¶, ùëè·µ£ che corrispondono al miglior valore della funzione di costo. Adatta il modello con .fit():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "#o per semplicit√† tutto su una riga\n",
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto abbiamo definito il modello di classificazione.\n",
    "\n",
    "Possiamo quindi ottenere rapidamente gli attributi del nostro modello, a esempio, l'attributo .classes_rappresenta l'array di valori distinti che y richiede, o possiamo anche ottenere il valore della pendenza ùëè‚ÇÅ e l'intercetta ùëè‚ÇÄ della funzione lineare ùëì:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.classes_)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le classi come abbiamo detto sono binarie nel nostro esempio (quindi 0 o 1), altra cosa che notiamo √® che ùëè‚ÇÄ √® contenuto in un array unidimensionale, mentre ùëè‚ÇÅ √® contenuto in un array bidimensionale. \n",
    "### Passaggio 4: valutare il modello\n",
    "Una volta definito un modello, √® possibile verificarne le prestazioni con .predict_proba(), che restituisce la matrice delle probabilit√† che l'output previsto sia uguale a zero o uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella matrice sopra, ogni riga corrisponde a una singola osservazione. La prima colonna √® la probabilit√† che il risultato previsto sia zero, ovvero 1 - ùëù(ùë•). La seconda colonna √® la probabilit√† che l'output sia uno, o ùëù(ùë•).\n",
    "\n",
    "Possiamo ottenere le previsioni effettive, basate sulla matrice di probabilit√† e sui valori di ùëù(ùë•), con .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione restituisce i valori di output previsti come matrice unidimensionale.\n",
    "\n",
    "La figura seguente illustra i risultati di input, output e classificazione:\n",
    "\n",
    "![grafico input regressione logistica](dati/img/log-reg-input.webp)\n",
    "\n",
    "I cerchi verdi rappresentano le risposte effettive e le previsioni corrette. La √ó rossa mostra la previsione errata. La linea nera completa √® la linea di regressione logistica stimata ùëù(ùë•). I quadrati grigi sono i punti su questa linea che corrispondono a ùë• e ai valori nella seconda colonna della matrice di probabilit√†. La linea tratteggiata nera √® il logit ùëì(ùë•).\n",
    "\n",
    "Il valore di X leggermente superiore a 2 corrisponde alla soglia ùëù(ùë•)=0,5, che √® ùëì(ùë•)=0. Questo valore di ùë• √® il confine tra i punti classificati come zero e quelli previsti come uno.\n",
    "\n",
    "Ad esempio, il primo punto ha input ùë•=0, output effettivo ùë¶=0, probabilit√† ùëù=0,26 e un valore previsto di 0. Il secondo punto ha ùë•=1, ùë¶=0, ùëù=0,37 e una previsione di 0. Solo il quarto punto ha l'output effettivo ùë¶=0 e la probabilit√† superiore a 0,5 (a ùëù=0,62), quindi √® erroneamente classificato come 1. Tutti gli altri valori sono previsti correttamente.\n",
    "\n",
    "Quando nove osservazioni su dieci sono classificate correttamente, la precisione del nostro modello √® pari a 9/10=0,9, che possiamo ottenere con .score():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".score() accetta l'input e l'output come argomenti e restituisce il rapporto tra il numero di previsioni corrette e il numero di osservazioni.\n",
    "\n",
    "Possiamo ottenere maggiori informazioni sull'accuratezza del modello con una matrice di confusione . Nel caso della classificazione binaria, la matrice di confusione mostra i numeri seguenti:\n",
    "\n",
    "- Veri negativi nella posizione in alto a sinistra\n",
    "- Falsi negativi nella posizione in basso a sinistra\n",
    "- Falsi positivi nella posizione in alto a destra\n",
    "- Veri positivi nella posizione in basso a destra\n",
    "Per creare la matrice di confusione, √® possibile utilizzare confusion_matrix() e fornire gli output effettivi e previsti come argomenti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice ottenuta mostra quanto segue:\n",
    "\n",
    "- Tre previsioni vere negative: le prime tre osservazioni sono zeri predetti correttamente.\n",
    "- Nessuna previsione falsa negativa: queste sono quelle erroneamente previste come zero.\n",
    "- Una previsione falsa positiva: la quarta osservazione √® uno zero che √® stato erroneamente previsto come uno.\n",
    "- Sei previsioni vere positive: le ultime sei osservazioni sono quelle previste correttamente.\n",
    "Spesso √® utile visualizzare la matrice di confusione. Possiamo farlo con .imshow() Matplotlib, che accetta la matrice di confusione come argomento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, model.predict(X))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice sopra crea una mappa termica che rappresenta la matrice di confusione\n",
    "\n",
    "In questa figura, colori diversi rappresentano numeri diversi e colori simili rappresentano numeri simili. Le mappe di calore sono un modo carino e conveniente per rappresentare una matrice.\n",
    "\n",
    "√à possibile ottenere un rapporto pi√π completo sulla classificazione con classification_report():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione accetta anche gli output effettivi e previsti come argomenti. Restituisce un report sulla classificazione come dizionario se fornito output_dict=True o una stringa altrimenti.\n",
    "\n",
    "Nota: in genere √® meglio valutare il modello con i dati non utilizzati per l'addestramento. In questo modo si evitano i bias e si rileva l'overfitting. \n",
    "\n",
    "\n",
    "### Migliorariamo il modello\n",
    "Possiamo migliorare il nostro modello impostando parametri diversi, a esempio lavoriamo con la forza di regolarizzazione C pari a 10.0, invece del valore predefinito di 1.0, cos√¨ da avere un altro modello con parametri diversi. Naturalmente avr√† anche una diversa matrice di probabilit√† e un diverso insieme di coefficienti e previsioni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(X, y)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n",
    "print(model.predict_proba(X))\n",
    "print(model.predict(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere, i valori assoluti dell'intercetta ùëè‚ÇÄ e del coefficiente ùëè‚ÇÅ sono maggiori. Questo perch√© il valore maggiore di C significa una regolarizzazione pi√π debole o una penalizzazione pi√π debole correlata a valori elevati di ùëè‚ÇÄ e ùëè‚ÇÅ.\n",
    "\n",
    "Valori diversi di ùëè‚ÇÄ e ùëè‚ÇÅ implicano un cambiamento del logit ùëì(ùë•), diversi valori delle probabilit√† ùëù(ùë•), una forma diversa della linea di regressione e possibilmente cambiamenti in altri risultati previsti e prestazioni di classificazione. Il valore limite di ùë• per il quale ùëù(ùë•)=0,5 e ùëì(ùë•)=0 √® ora pi√π alto, √® superiore a 3. In questo caso, ottieniamo tutte le previsioni vere, come vedremo dall'accuratezza, dalla matrice di confusione e dal rapporto di classificazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X, y))\n",
    "print(confusion_matrix(y, model.predict(X)))\n",
    "print(classification_report(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il punteggio (o la precisione) di 1 e gli zeri nei campi in basso a sinistra e in alto a destra della matrice di confusione indicano che i risultati effettivi e quelli previsti sono gli stessi. Ci√≤ √® mostrato anche nella figura seguente:\n",
    "\n",
    "![grafico input regressione logistica](dati/img/log-reg-input2.webp)\n",
    "\n",
    "Questa figura illustra che la linea di regressione stimata ora ha una forma diversa e che il quarto punto √® classificato correttamente come 0. Non c'√® una x rossa, quindi non c'√® una previsione sbagliata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altro problema di classificazione\n",
    "Risolviamo un altro problema di classificazione, simile al precedente, tranne per il fatto che l'output differisce nel secondo valore. \n",
    "Il codice √® quindi simile al caso precedente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages, functions, and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Get data\n",
    "X = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Step 3: Create a model and train it\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "p_pred = model.predict_proba(X)\n",
    "y_pred = model.predict(X)\n",
    "score_ = model.score(X, y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo esempio di codice di classificazione genera i seguenti risultati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X:', X, sep='\\n')\n",
    "\n",
    "print('y:', y, sep='\\n', end='\\n\\n')\n",
    "\n",
    "print('intercept:', model.intercept_)\n",
    "\n",
    "print('coef:', model.coef_, end='\\n\\n')\n",
    "\n",
    "print('p_pred:', p_pred, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_pred:', y_pred, end='\\n\\n')\n",
    "\n",
    "print('score_:', score_, end='\\n\\n')\n",
    "\n",
    "print('conf_m:', conf_m, sep='\\n', end='\\n\\n')\n",
    "\n",
    "print('report:', report, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso, il punteggio (o la precisione) √® 0,8. Ci sono due osservazioni classificate in modo errato. Una di queste √® un falso negativo, mentre l'altra √® un falso positivo.\n",
    "\n",
    "La figura seguente illustra questo esempio con otto previsioni corrette e due errate:\n",
    "\n",
    "![grafico input regressione logistica](dati/img/log-reg-input3.webp)\n",
    "\n",
    "Questa figura rivela una caratteristica importante di questo esempio, a differenza del precedente questo problema non √® linearmente separabile . \n",
    "Ci√≤ significa che non possiamo trovare un valore di ùë• e tracciare una linea retta per separare le osservazioni con ùë¶=0 e quelle con ùë¶=1. Non esiste una linea del genere.  \n",
    "La regressione logistica √® infatti essenzialmente un classificatore lineare, quindi teoricamente non possiamo creare un modello di regressione logistica con una precisione pari a 1 in questo caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressione logistica in Python con scikit-learn: Esempio 2\n",
    "Partiamo nell'importare le librerie e creare i due set d'esempio, X che reppresenta la grandezza di un tumore in cm, y se il tumore √® maligno (0 per \"No\", 1 per \"Si\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import linear_model\n",
    "\n",
    "X = numpy.array([3.78, 2.44, 2.09, 0.14, 1.72, 1.65, 4.92, 4.37, 4.96, 4.52, 3.69, 5.88]).reshape(-1,1)\n",
    "\n",
    "y = numpy.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dal modulo sklearn utilizzeremo il metodo LogisticRegression() per creare un oggetto di regressione logistica e il suo metodo fit() che prende i valori indipendenti e dipendenti come parametri e riempie l'oggetto di regressione con i dati che descrivono la relazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto usiamo l'oggetto di regressione logistica per stabilire se un tumore √® canceroso in base alle dimensioni del tumore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict if tumor is cancerous where the size is 3.46mm:\n",
    "predicted = logr.predict(numpy.array([3.46]).reshape(-1,1))\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a vedere il coefficiente √® la variazione attesa nelle probabilit√† logaritmiche di ottenere una variazione unitaria del risultato in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds = logr.coef_\n",
    "odds = numpy.exp(log_odds)\n",
    "\n",
    "print(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo ci dice che quando la dimensione di un tumore aumenta di 1 mm, le probabilit√† che si tratti di un tumore canceroso aumentano di 4 volte.\n",
    "\n",
    "Possiamo quindi usare il coefficiente e i valori dell'intercetta per trovare la probabilit√† che ciascun tumore sia canceroso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit2prob(logr,x):\n",
    "  \n",
    "  #Per trovare le probabilit√† logaritmiche per ciascuna osservazione, \n",
    "  #dobbiamo prima creare una formula simile a quella della regressione lineare, estraendo il coefficiente e l'intercetta.  \n",
    "  log_odds = logr.coef_ * x + logr.intercept_\n",
    "  \n",
    "  #Per poi convertire le probabilit√† logaritmiche in quote dobbiamo renderle esponenziali.\n",
    "  odds = numpy.exp(log_odds)\n",
    "\n",
    "  #Ora che abbiamo le quote, possiamo convertirle in probabilit√† dividendole per 1 pi√π le quote.\n",
    "  probability = odds / (1 + odds)\n",
    "  return(probability)\n",
    "\n",
    "print(logit2prob(logr, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi:\n",
    "\n",
    "- per X = 3,78, La probabilit√† che un tumore delle dimensioni di 3,78 cm sia canceroso √® del 61%.\n",
    "\n",
    "- per X = 2,44, La probabilit√† che un tumore delle dimensioni di 2,44 cm sia canceroso √® del 19%.\n",
    "\n",
    "- per X =2,09, La probabilit√† che un tumore delle dimensioni di 2,09 cm sia canceroso √® del 13%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressione logistica in Python con scikit-learn: Esempio 3 Fiori Iris\n",
    "In questo esempio partiamo dal dataset di scikit-learn sui fiori iris, il set di dati classifica 3 diversi tipi di fiori (Setosa, Versicolor e Virginica) in base a lunghezza dei petali e dei sepali dell'iride.\n",
    "Le righe rappresentano i campioni e le colonne sono: Lunghezza sepalo, Larghezza sepalo, Lunghezza petalo e Larghezza petalo.\n",
    "\n",
    "Utilizziamo quindi i dati di larghezza e lunghezza dei sepali (il botanica il termine \"sepali\" indica quegli elementi di derivazione fogliare che formano il calice del fiore.) per capire di quale dei tre tipi di fiori iris fanno parte e poi visualizziamo un grafico che ne mostra le differenze.\n",
    "\n",
    "![sepali](dati/img/sepali.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, Y)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    logreg,\n",
    "    X,\n",
    "    cmap=plt.cm.Paired,\n",
    "    ax=ax,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    shading=\"auto\",\n",
    "    xlabel=\"Sepal length\",\n",
    "    ylabel=\"Sepal width\",\n",
    "    eps=0.5,\n",
    ")\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors=\"k\", cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "var =classification_report(logreg.predict(X),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(logreg.predict(X),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test =train_test_split(X, Y)\n",
    "\n",
    "\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    logreg,\n",
    "    x_train,\n",
    "    cmap=plt.cm.Paired,\n",
    "    ax=ax,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    shading=\"auto\",\n",
    "    xlabel=\"Sepal length\",\n",
    "    ylabel=\"Sepal width\",\n",
    "    eps=0.5,\n",
    ")\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, edgecolors=\"k\", cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "var =classification_report(logreg.predict(x_test),y_test)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(logreg.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 1\n",
    "Partendo dal dataset al seguente link https://raw.githubusercontent.com/madmashup/targeted-marketing-predictive-engine/master/banking.csv relativo a campagne di marketing diretto (telefonate) di un istituto bancario portoghese, create il modello pi√π preciso possibile per prevedere se il cliente sottoscriver√† (1/0) un deposito a termine(variabile y).\n",
    "\n",
    "Nel dataset abbiamo le seguenti colonne:\n",
    "\n",
    "#### Variabili di input\n",
    "\n",
    "- et√† (numerico)\n",
    "- lavoro: tipologia di lavoro (categoriale: ‚Äúamministratore‚Äù, ‚Äúoperaio‚Äù, ‚Äúimprenditore‚Äù, ‚Äúcameriera‚Äù, ‚Äúdirigente‚Äù, ‚Äúpensionato‚Äù, ‚Äúlavoratore autonomo‚Äù, ‚Äúservizi‚Äù, ‚Äústudente‚Äù, ‚Äútecnico‚Äù ‚Äù, ‚Äúdisoccupato‚Äù, ‚Äúsconosciuto‚Äù)\n",
    "- coniugale: stato civile (categorico: ‚Äúdivorziato‚Äù, ‚Äúsposato‚Äù, ‚Äúcelibe‚Äù, ‚Äúsconosciuto‚Äù)\n",
    "- istruzione (categoriale: ‚Äúbasic.4a‚Äù, ‚Äúbasic.6a‚Äù, ‚Äúbasic.9a‚Äù, ‚Äúscuola superiore‚Äù, ‚Äúanalfabeta‚Äù, ‚Äúcorso.professionale‚Äù, ‚Äúlaurea.universitaria‚Äù, ‚Äúsconosciuto‚Äù)\n",
    "- default: ha credito in default? (categorico: ‚Äúno‚Äù, ‚Äús√¨‚Äù, ‚Äúsconosciuto‚Äù)\n",
    "- alloggio: ha mutuo per la casa? (categorico: ‚Äúno‚Äù, ‚Äús√¨‚Äù, ‚Äúsconosciuto‚Äù)\n",
    "- prestito: ha prestito personale? (categorico: ‚Äúno‚Äù, ‚Äús√¨‚Äù, ‚Äúsconosciuto‚Äù)\n",
    "- contatto: tipo di comunicazione del contatto (categoriale: ‚Äúcellulare‚Äù, ‚Äútelefonico‚Äù)\n",
    "- mese: mese dell'anno dell'ultimo contatto (categoriale: ‚Äúgen‚Äù, ‚Äúfeb‚Äù, ‚Äúmar‚Äù, ‚Ä¶, ‚Äúnov‚Äù, ‚Äúdic‚Äù)\n",
    "- day_of_week: ultimo giorno di contatto della settimana (categorico: ‚Äúmon‚Äù, ‚Äúmar‚Äù, ‚Äúmer‚Äù, ‚Äúgio‚Äù, ‚Äúven‚Äù)\n",
    "- durata: durata dell'ultimo contatto, in secondi (numerico). Nota importante: questo attributo influisce notevolmente sulla destinazione dell'output (ad esempio, se durata=0 allora y='no'). La durata non √® nota prima che venga effettuata una chiamata, inoltre, dopo la fine della chiamata, √® ovviamente nota y. Pertanto, questo input dovrebbe essere incluso solo a fini di benchmark e dovrebbe essere scartato se l‚Äôintenzione √® quella di avere un modello predittivo realistico\n",
    "- campagna: numero di contatti eseguiti durante questa campagna e per questo cliente (numerico, include l'ultimo contatto)\n",
    "- pdays: numero di giorni trascorsi dall'ultimo contatto del cliente da una campagna precedente (numerico; 999 significa che il cliente non √® stato contattato in precedenza)\n",
    "- precedente: numero di contatti effettuati prima di questa campagna e per questo cliente (numerico)\n",
    "- poutcome: esito della precedente campagna di marketing (categoriale: ‚Äúfallimento‚Äù, ‚Äúinesistente‚Äù, ‚Äúsuccesso‚Äù)\n",
    "- emp.var.rate: tasso di variazione dell'occupazione ‚Äî (numerico)\n",
    "- cons.price.idx: indice dei prezzi al consumo ‚Äî (numerico)\n",
    "- cons.conf.idx: indice di fiducia dei consumatori ‚Äî (numerico)\n",
    "- euribor3m: tasso euribor a 3 mesi ‚Äî (numerico)\n",
    "- nr.occupati: numero di dipendenti ‚Äî (numerico)\n",
    "\n",
    "### Variabile output (obiettivo desiderato):\n",
    "\n",
    "- y ‚Äî il cliente ha sottoscritto un deposito a termine? (binario: ‚Äú1‚Äù, significa ‚ÄúS√¨‚Äù, ‚Äú0‚Äù significa ‚ÄúNo‚Äù)\n",
    "\n",
    "\n",
    "## Valutate se utilizzare tutti i paramentri o solo alcuni di essi:\n",
    "\n",
    "## - Create il modello e addestratelo;\n",
    "## - Valutate il modello;\n",
    "## - Create la matrice di confusione;\n",
    "## - Create un report di classificazione\n",
    "## - Create i grafici"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
